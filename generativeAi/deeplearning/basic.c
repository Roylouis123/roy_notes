/*
 * Deep Learning
 * It is a subset of machine learning in artificial intelligence (AI) that involves
 * neural networks with three or more layers. These neural networks attempt to simulate the
 * behavior of the human brain in processing data for use in decision making, pattern recognition,
 * and feature extraction.
 *
 * Types of Deep Learning Architectures
 * ------------------------------------
 */


/**
 * Artificial Neural Networks (ANN)
 * --------------------------------
 *
 * Description: ANN is a computational model inspired by the structure and function of the human
 * brain. It is composed of interconnected nodes (neurons) that receive inputs, perform computations,
 * and produce outputs.
 *
 * Use Cases: Pattern recognition, image and speech recognition, natural language processing, decision making,
 * recommendation systems, and more.
 */

/**
 * Feedforward Neural Networks (FNN)
 * --------------------------------
 *
 * Description: The simplest type of artificial neural network. Information moves in one direction
 * (forward) from the input nodes, through the hidden nodes (if any), and to the output nodes.
 *
 * Use Cases: Basic pattern recognition, image recognition.
 */

/**
 * Convolutional Neural Networks (CNN)
 * ------------------------------------
 *
 * Description: Specialized for processing structured grid data like images. It uses convolutional
 * layers that apply a convolution operation to the input, passing the result to the next layer.
 *
 * Use Cases: Image and video recognition, image classification, medical image analysis, and self-driving cars.
 */

/**
 * Recurrent Neural Networks (RNN)
 * --------------------------------
 *
 * Description: Suitable for sequential data. It has connections that form directed cycles, allowing
 * the network to maintain a memory of previous inputs. Variants include Long Short-Term Memory
 * (LSTM) and Gated Recurrent Unit (GRU) networks.
 *
 * Use Cases: Time series prediction, natural language processing, speech recognition, and machine translation.
 */

/**
 * Generative Adversarial Networks (GAN)
 * ---------------------------------------
 *
 * Description: Consists of two networks, a generator and a discriminator, which compete against each other.
 * The generator creates data, and the discriminator evaluates it.
 *
 * Use Cases: Image generation, video generation, and creating realistic data samples.
 */

/**
 * Autoencoders
 * -------------
 *
 * Description: Used for unsupervised learning. They aim to learn a compressed representation of the input data,
 * called encoding, and then reconstruct the input from this encoding.
 *
 * Use Cases: Dimensionality reduction, image denoising, and anomaly detection.
 */

/**
 * Deep Belief Networks (DBN)
 * --------------------------
 *
 * Description: Composed of multiple layers of stochastic, latent variables. Each layer is a Restricted
 * Boltzmann Machine (RBM), a type of neural network used for learning a probability distribution over a set of inputs.
 *
 * Use Cases: Feature extraction, data pre-training, and unsupervised learning tasks.
 */

/**
 * Transformer Networks
 * ---------------------
 *
 * Description: Utilizes self-attention mechanisms to process sequential data, which allows it to handle
 * dependencies regardless of their distance in the sequence.
 *
 * Use Cases: Natural language processing tasks like translation, text summarization, and language modeling.
 */


